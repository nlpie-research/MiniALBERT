# MiniALBERT
This project contains the code for training/fine-tuning the models used in the paper "MiniALBERT: Model Distillation via Parameter-Efficient Recursive Transformers".
